{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.7 모델 세부 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7.0 이전 내용 복습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "\n",
    "## 데이터 추출 함수\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = 'https://raw.githubusercontent.com/ageron/handson-ml2/master/'\n",
    "HOUSING_PATH = '../' + os.path.join('datasets', 'housing')\n",
    "HOUSING_URL = DOWNLOAD_ROOT + 'datasets/housing/housing.tgz'\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    \"\"\"\n",
    "    현재 작업 공간에 \"datasets/housing\" 디렉터리 생성\n",
    "    housing.tgz 파일 내려받음\n",
    "    같인 디렉터리에 압축을 풀어 \"housing.csv\" 파일 생성\n",
    "    \"\"\"\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, 'housing.tgz')\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "    \n",
    "#fetch_housing_data(HOUSING_URL, HOUSING_PATH)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "## 데이터 읽기 함수\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, 'housing.csv')\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()\n",
    "#housing.head()\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "## 테스트 세트 분리\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# income_cat 특성 생성\n",
    "housing['income_cat'] = pd.cut(housing['median_income'],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing['income_cat']):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "    \n",
    "# income_cat 특성 삭제\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop('income_cat', axis=1, inplace=True)\n",
    "    \n",
    "#print('strat_train_set size : {}'.format(len(strat_train_set)))\n",
    "#print('strat_test_set size : {}'.format(len(strat_test_set)))\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "## 훈련 세트 예측 변수와 레이블 분리\n",
    "\n",
    "# drop()은 데이터 복사본을 만들며 strat_train_set에 영향을 주지 않음\n",
    "housing = strat_train_set.drop('median_house_value', axis=1)\n",
    "housing_labels = strat_train_set['median_house_value'].copy()\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "## 변환 파이프 라인\n",
    "\n",
    "# 특성 조합 변환기 정의\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "col_names = \"total_rooms\", \"total_bedrooms\", \"population\", \"households\"\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = [housing.columns.get_loc(c) for c in col_names]\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # *args 나 **kargs 가 아님\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room  \n",
    "    def fit(self, X, y=None):\n",
    "        return self # 더 이상 할 일이 없음\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix] # 가구당 방 갯수\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix] # 가구당 인구수\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix] # 방 당 화장실 갯수\n",
    "            return np.c_[X, \n",
    "                         rooms_per_household,\n",
    "                         population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, \n",
    "                         rooms_per_household,\n",
    "                         population_per_household]\n",
    "\n",
    "# 수치형 특성 변환 파이프라인\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')), # 결측치 처리\n",
    "    ('attribs_adder', CombinedAttributesAdder()), # 특성 조합\n",
    "    ('std_scaler', StandardScaler()) # 수치형 특성 데이터 스케일링\n",
    "])\n",
    "\n",
    "# 통합 변환 파이프라인\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "housing_num = housing.drop('ocean_proximity', axis=1)\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = ['ocean_proximity']\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attribs),\n",
    "    ('cat', OneHotEncoder(), cat_attribs) # 범주형 특성 데이터 숫자 변환\n",
    "])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "#housing_prepared\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "## 모델 훈련\n",
    "\n",
    "# 선형 회귀\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# 의사결정나무 - 회귀\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# 랜덤 포레스트 - 회귀\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# 서포트 벡터 머신\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel='linear')\n",
    "svm_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "## 평가 함수 정의\n",
    "\n",
    "# RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def get_RMSE(model, X, y):\n",
    "    predictions = model.predict(X)\n",
    "    mse = mean_squared_error(y, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "## K-겹 교차 검증\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def k_fold_cross_validation(model, X, y, cv=10):\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    return rmse_scores\n",
    "\n",
    "def display_scores(scores):\n",
    "    print('점수:\\n', scores)\n",
    "    print('평균:\\n', scores.mean())\n",
    "    print('표준편차:\\n', scores.std())\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "## 전처리와 예측을 포함한 전체 파이프라인 및 모델 저장, 불러오기\n",
    "\n",
    "# 전처리와 예측을 포함한 전체 파이프라인\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "    ('preparation', full_pipeline),\n",
    "    ('linear', LinearRegression())\n",
    "])\n",
    "\n",
    "full_pipeline_with_predictor.fit(housing, housing_labels)\n",
    "\n",
    "# 모델 저장\n",
    "import joblib\n",
    "\n",
    "my_model = full_pipeline_with_predictor\n",
    "joblib.dump(my_model, '../models/my_model_ch02.pkl') # DIFF\n",
    "\n",
    "# 모델 불러오기\n",
    "my_model_loaded = joblib.load('../models/my_model_ch02.pkl')\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression's RMSE :  68628.19819848923\n",
      "decision tree regression's RMSE :  0.0\n",
      "randomforest regression's RMSE :  22001.205898052976\n",
      "SVM regression's RMSE :  111094.6308539982\n"
     ]
    }
   ],
   "source": [
    "print(\"linear regression's RMSE : \", get_RMSE(lin_reg, housing_prepared, housing_labels))\n",
    "print(\"decision tree regression's RMSE : \", get_RMSE(tree_reg, housing_prepared, housing_labels))\n",
    "print(\"randomforest regression's RMSE : \", get_RMSE(forest_reg, housing_prepared, housing_labels))\n",
    "print(\"SVM regression's RMSE : \", get_RMSE(svm_reg, housing_prepared, housing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression's 10-fold cross validation scores:\n",
      "\n",
      "점수:\n",
      " [66782.73843989 66960.118071   70347.95244419 74739.57052552\n",
      " 68031.13388938 71193.84183426 64969.63056405 68281.61137997\n",
      " 71552.91566558 67665.10082067]\n",
      "평균:\n",
      " 69052.46136345083\n",
      "표준편차:\n",
      " 2731.6740017983484\n"
     ]
    }
   ],
   "source": [
    "lin_scores = k_fold_cross_validation(lin_reg, housing_prepared, housing_labels, 10)\n",
    "print(\"linear regression's 10-fold cross validation scores:\\n\")\n",
    "display_scores(lin_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomForest regression's 10-fold cross validation scores:\n",
      "\n",
      "점수:\n",
      " [52401.63707617 50397.90294879 52122.37342201 54072.02422854\n",
      " 52689.30017448 56126.4034412  50393.46220378 50781.06926795\n",
      " 55699.76701831 52543.76280404]\n",
      "평균:\n",
      " 52722.770258526005\n",
      "표준편차:\n",
      " 1933.0123740301037\n"
     ]
    }
   ],
   "source": [
    "forest_scores = k_fold_cross_validation(forest_reg, housing_prepared, housing_labels, 10)\n",
    "print(\"randomForest regression's 10-fold cross validation scores:\\n\")\n",
    "display_scores(forest_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2.7.1 그리드 탐색\n",
    "\n",
    "- 튜닝의 가장 단순한 방법\n",
    "  - 만족할 만한 하이퍼파라미터 조합을 찾을 때 까지 수동으로 하이퍼파라미터를 조정하는 것\n",
    "  - 사이킷런의 `GridSearchCV`를 사용하는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.7.1.1 `GridSearchCV` 을 통한 그리드 탐색\n",
    "\n",
    "- 탐색하고자 하는 하이퍼파라미터와 시도해볼 값을 지정하기만 하면 된다.\n",
    "- 그러면 가능한 모든 하이퍼파라미터 조합에 대해 교차 검증을 사용해 평가하게 된다.\n",
    "- 어떤 하이퍼파라미터 값을 지정해야 할 지 모를 때는 **연속된 10의 거듭제곱 수**로 시도해보는 것이 좋다.\n",
    "  - 더 세밀하게 탐색하려면 아래 예제의 `n_estimators` 하이퍼파라미터처럼 더 작은 값을 지정한다.  \n",
    "  \n",
    "  \n",
    "- `GridSearchCV`가 (기본값인) `refit=True`로 초기화되었다면, 교차 검증으로 최적의 추정기를 찾은 다음 전체 훈련 세트로 다시 훈련 시킨다.\n",
    "  - 일반적으로 데이터가 많을수록 성능이 향상되므로 좋은 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `RandomForestRegressor`에 대한 최적의 하이퍼파라미터 조합 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]}\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg,\n",
    "                           param_grid,\n",
    "                           cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `param_grid` 설정에 따라 사이킷런이 다음과 같은 과정을 수행한다.  \n",
    "  \n",
    "  \n",
    "1. 첫 번째 dict에 있는 `n_estimators`와 `max_features` 하이퍼파라미터의 조합인 3x4=12개를 시도한다.\n",
    "2. 두 번째 dict에 있는 하이퍼파라미터 조합인 2x3=6개를 시도한다.\n",
    "  - 두 번째 dict에는 `bootstrap` 하이퍼파라미터를 `True`(기본값)가 아니라 `False`로 지정한다.\n",
    "3. 모두 합하면 그리드 탐색이 `RandomForestRegressor` 하이퍼파라미터 값의 18(=12+6)개 조합을 탐색하고, 각각 다섯 번 모델을 훈련시킨다.\n",
    "  - `cv=5` 이기 때문에 5-겹 교차 검증을 사용  \n",
    "  \n",
    "  \n",
    "- 최종적으로 전체 훈련 횟수는 18x5=90 이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.7.1.2 최적의 조합 확인\n",
    "\n",
    "- 90번의 훈련을 시키는 것이 시간이 꽤 오래 걸리지만 다음과 같이 최적의 조합을 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 8, 'n_estimators': 30}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최적의 조합의 값들이 탐색 범위의 최댓값이기 때문에 계속 점수가 향상될 가능성이 있다.\n",
    "- 그러므로 더 큰 값으로 다시 검색해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.7.1.3 최적의 추정기 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features=8, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=30,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.7.1.4 평가 점수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'mean_train_score',\n",
       " 'param_bootstrap',\n",
       " 'param_max_features',\n",
       " 'param_n_estimators',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split0_train_score',\n",
       " 'split1_test_score',\n",
       " 'split1_train_score',\n",
       " 'split2_test_score',\n",
       " 'split2_train_score',\n",
       " 'split3_test_score',\n",
       " 'split3_train_score',\n",
       " 'split4_test_score',\n",
       " 'split4_train_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score',\n",
       " 'std_train_score']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "sorted(list(cvres.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.072207</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 3}</td>\n",
       "      <td>-3.716722e+09</td>\n",
       "      <td>-4.313661e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.116607e+09</td>\n",
       "      <td>2.563509e+08</td>\n",
       "      <td>18</td>\n",
       "      <td>-1.083079e+09</td>\n",
       "      <td>-1.047389e+09</td>\n",
       "      <td>-1.127826e+09</td>\n",
       "      <td>-1.109980e+09</td>\n",
       "      <td>-1.106520e+09</td>\n",
       "      <td>-1.094959e+09</td>\n",
       "      <td>2.772560e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.253921</td>\n",
       "      <td>0.011312</td>\n",
       "      <td>0.011562</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 10}</td>\n",
       "      <td>-2.850491e+09</td>\n",
       "      <td>-3.119997e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.027606e+09</td>\n",
       "      <td>1.668264e+08</td>\n",
       "      <td>11</td>\n",
       "      <td>-6.173649e+08</td>\n",
       "      <td>-5.641315e+08</td>\n",
       "      <td>-5.666449e+08</td>\n",
       "      <td>-5.771149e+08</td>\n",
       "      <td>-5.799831e+08</td>\n",
       "      <td>-5.810479e+08</td>\n",
       "      <td>1.912663e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.748794</td>\n",
       "      <td>0.035522</td>\n",
       "      <td>0.031113</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 30}</td>\n",
       "      <td>-2.639959e+09</td>\n",
       "      <td>-2.911493e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.811365e+09</td>\n",
       "      <td>1.493787e+08</td>\n",
       "      <td>8</td>\n",
       "      <td>-4.440819e+08</td>\n",
       "      <td>-4.238242e+08</td>\n",
       "      <td>-4.273691e+08</td>\n",
       "      <td>-4.469485e+08</td>\n",
       "      <td>-4.238588e+08</td>\n",
       "      <td>-4.332165e+08</td>\n",
       "      <td>1.016464e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.136435</td>\n",
       "      <td>0.013608</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 3}</td>\n",
       "      <td>-3.585587e+09</td>\n",
       "      <td>-3.762455e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.720020e+09</td>\n",
       "      <td>1.536307e+08</td>\n",
       "      <td>16</td>\n",
       "      <td>-1.011239e+09</td>\n",
       "      <td>-9.914131e+08</td>\n",
       "      <td>-9.562032e+08</td>\n",
       "      <td>-1.022028e+09</td>\n",
       "      <td>-9.184196e+08</td>\n",
       "      <td>-9.798606e+08</td>\n",
       "      <td>3.802849e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.395148</td>\n",
       "      <td>0.023099</td>\n",
       "      <td>0.010778</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 10}</td>\n",
       "      <td>-2.674733e+09</td>\n",
       "      <td>-3.042027e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.838169e+09</td>\n",
       "      <td>1.510512e+08</td>\n",
       "      <td>9</td>\n",
       "      <td>-5.443797e+08</td>\n",
       "      <td>-5.544777e+08</td>\n",
       "      <td>-5.250524e+08</td>\n",
       "      <td>-5.060819e+08</td>\n",
       "      <td>-5.235322e+08</td>\n",
       "      <td>-5.307048e+08</td>\n",
       "      <td>1.698137e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.099065</td>\n",
       "      <td>0.081386</td>\n",
       "      <td>0.026922</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 30}</td>\n",
       "      <td>-2.338585e+09</td>\n",
       "      <td>-2.597113e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.543872e+09</td>\n",
       "      <td>1.482446e+08</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.018289e+08</td>\n",
       "      <td>-3.936587e+08</td>\n",
       "      <td>-3.813845e+08</td>\n",
       "      <td>-4.004283e+08</td>\n",
       "      <td>-3.855221e+08</td>\n",
       "      <td>-3.925645e+08</td>\n",
       "      <td>8.043081e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.150803</td>\n",
       "      <td>0.008874</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 3}</td>\n",
       "      <td>-3.597163e+09</td>\n",
       "      <td>-3.487085e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.524766e+09</td>\n",
       "      <td>1.202082e+08</td>\n",
       "      <td>14</td>\n",
       "      <td>-9.297786e+08</td>\n",
       "      <td>-8.891628e+08</td>\n",
       "      <td>-9.481490e+08</td>\n",
       "      <td>-9.182473e+08</td>\n",
       "      <td>-9.067466e+08</td>\n",
       "      <td>-9.184168e+08</td>\n",
       "      <td>2.002556e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.503059</td>\n",
       "      <td>0.033011</td>\n",
       "      <td>0.009966</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 10}</td>\n",
       "      <td>-2.531234e+09</td>\n",
       "      <td>-2.723348e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.675294e+09</td>\n",
       "      <td>1.335638e+08</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.077070e+08</td>\n",
       "      <td>-4.978420e+08</td>\n",
       "      <td>-4.958105e+08</td>\n",
       "      <td>-5.085082e+08</td>\n",
       "      <td>-4.941817e+08</td>\n",
       "      <td>-5.008099e+08</td>\n",
       "      <td>6.075659e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.442559</td>\n",
       "      <td>0.041349</td>\n",
       "      <td>0.026115</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 30}</td>\n",
       "      <td>-2.322851e+09</td>\n",
       "      <td>-2.560697e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.486072e+09</td>\n",
       "      <td>1.252884e+08</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.848096e+08</td>\n",
       "      <td>-3.722657e+08</td>\n",
       "      <td>-3.703482e+08</td>\n",
       "      <td>-3.916076e+08</td>\n",
       "      <td>-3.767458e+08</td>\n",
       "      <td>-3.791554e+08</td>\n",
       "      <td>7.973333e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.191877</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 3}</td>\n",
       "      <td>-3.211023e+09</td>\n",
       "      <td>-3.553599e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.399507e+09</td>\n",
       "      <td>1.295960e+08</td>\n",
       "      <td>12</td>\n",
       "      <td>-8.762917e+08</td>\n",
       "      <td>-8.958030e+08</td>\n",
       "      <td>-8.885024e+08</td>\n",
       "      <td>-9.027841e+08</td>\n",
       "      <td>-8.944754e+08</td>\n",
       "      <td>-8.915713e+08</td>\n",
       "      <td>8.887662e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.617558</td>\n",
       "      <td>0.030354</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 10}</td>\n",
       "      <td>-2.569061e+09</td>\n",
       "      <td>-2.789060e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.728464e+09</td>\n",
       "      <td>1.512255e+08</td>\n",
       "      <td>6</td>\n",
       "      <td>-5.103001e+08</td>\n",
       "      <td>-5.063813e+08</td>\n",
       "      <td>-4.867061e+08</td>\n",
       "      <td>-5.259273e+08</td>\n",
       "      <td>-5.041240e+08</td>\n",
       "      <td>-5.066878e+08</td>\n",
       "      <td>1.256299e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.914277</td>\n",
       "      <td>0.038379</td>\n",
       "      <td>0.034310</td>\n",
       "      <td>0.011847</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 30}</td>\n",
       "      <td>-2.353522e+09</td>\n",
       "      <td>-2.518849e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.478082e+09</td>\n",
       "      <td>1.105207e+08</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.878266e+08</td>\n",
       "      <td>-3.755611e+08</td>\n",
       "      <td>-3.677518e+08</td>\n",
       "      <td>-3.860005e+08</td>\n",
       "      <td>-3.801933e+08</td>\n",
       "      <td>-3.794667e+08</td>\n",
       "      <td>7.288349e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.113104</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 2, 'n_est...</td>\n",
       "      <td>-3.659144e+09</td>\n",
       "      <td>-3.943092e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.858075e+09</td>\n",
       "      <td>2.061109e+08</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.367628</td>\n",
       "      <td>0.012384</td>\n",
       "      <td>0.011564</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 2, 'n_est...</td>\n",
       "      <td>-2.863479e+09</td>\n",
       "      <td>-3.184515e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.002355e+09</td>\n",
       "      <td>1.371263e+08</td>\n",
       "      <td>10</td>\n",
       "      <td>-2.439095e+02</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-4.878189e+01</td>\n",
       "      <td>9.756378e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.148606</td>\n",
       "      <td>0.020423</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 3, 'n_est...</td>\n",
       "      <td>-3.380601e+09</td>\n",
       "      <td>-3.429445e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.566669e+09</td>\n",
       "      <td>2.493520e+08</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.470555</td>\n",
       "      <td>0.036233</td>\n",
       "      <td>0.010965</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 3, 'n_est...</td>\n",
       "      <td>-2.714781e+09</td>\n",
       "      <td>-2.712905e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.748078e+09</td>\n",
       "      <td>8.888762e+07</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.174133</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 4, 'n_est...</td>\n",
       "      <td>-3.438860e+09</td>\n",
       "      <td>-3.557646e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.488065e+09</td>\n",
       "      <td>3.979269e+07</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.572066</td>\n",
       "      <td>0.021418</td>\n",
       "      <td>0.011369</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 4, 'n_est...</td>\n",
       "      <td>-2.575274e+09</td>\n",
       "      <td>-2.733132e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.690139e+09</td>\n",
       "      <td>8.754169e+07</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-3.876145e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-9.462528e+02</td>\n",
       "      <td>-2.422407e-01</td>\n",
       "      <td>-1.900742e+02</td>\n",
       "      <td>3.780922e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.072207      0.007096         0.003397        0.000496   \n",
       "1        0.253921      0.011312         0.011562        0.001361   \n",
       "2        0.748794      0.035522         0.031113        0.002783   \n",
       "3        0.136435      0.013608         0.003790        0.000399   \n",
       "4        0.395148      0.023099         0.010778        0.000762   \n",
       "5        1.099065      0.081386         0.026922        0.001989   \n",
       "6        0.150803      0.008874         0.003192        0.000399   \n",
       "7        0.503059      0.033011         0.009966        0.001099   \n",
       "8        1.442559      0.041349         0.026115        0.002223   \n",
       "9        0.191877      0.012946         0.004378        0.001336   \n",
       "10       0.617558      0.030354         0.009772        0.000746   \n",
       "11       1.914277      0.038379         0.034310        0.011847   \n",
       "12       0.113104      0.006228         0.003992        0.000631   \n",
       "13       0.367628      0.012384         0.011564        0.001856   \n",
       "14       0.148606      0.020423         0.003393        0.000489   \n",
       "15       0.470555      0.036233         0.010965        0.001093   \n",
       "16       0.174133      0.005066         0.003795        0.000400   \n",
       "17       0.572066      0.021418         0.011369        0.002057   \n",
       "\n",
       "   param_max_features param_n_estimators param_bootstrap  \\\n",
       "0                   2                  3             NaN   \n",
       "1                   2                 10             NaN   \n",
       "2                   2                 30             NaN   \n",
       "3                   4                  3             NaN   \n",
       "4                   4                 10             NaN   \n",
       "5                   4                 30             NaN   \n",
       "6                   6                  3             NaN   \n",
       "7                   6                 10             NaN   \n",
       "8                   6                 30             NaN   \n",
       "9                   8                  3             NaN   \n",
       "10                  8                 10             NaN   \n",
       "11                  8                 30             NaN   \n",
       "12                  2                  3           False   \n",
       "13                  2                 10           False   \n",
       "14                  3                  3           False   \n",
       "15                  3                 10           False   \n",
       "16                  4                  3           False   \n",
       "17                  4                 10           False   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0              {'max_features': 2, 'n_estimators': 3}      -3.716722e+09   \n",
       "1             {'max_features': 2, 'n_estimators': 10}      -2.850491e+09   \n",
       "2             {'max_features': 2, 'n_estimators': 30}      -2.639959e+09   \n",
       "3              {'max_features': 4, 'n_estimators': 3}      -3.585587e+09   \n",
       "4             {'max_features': 4, 'n_estimators': 10}      -2.674733e+09   \n",
       "5             {'max_features': 4, 'n_estimators': 30}      -2.338585e+09   \n",
       "6              {'max_features': 6, 'n_estimators': 3}      -3.597163e+09   \n",
       "7             {'max_features': 6, 'n_estimators': 10}      -2.531234e+09   \n",
       "8             {'max_features': 6, 'n_estimators': 30}      -2.322851e+09   \n",
       "9              {'max_features': 8, 'n_estimators': 3}      -3.211023e+09   \n",
       "10            {'max_features': 8, 'n_estimators': 10}      -2.569061e+09   \n",
       "11            {'max_features': 8, 'n_estimators': 30}      -2.353522e+09   \n",
       "12  {'bootstrap': False, 'max_features': 2, 'n_est...      -3.659144e+09   \n",
       "13  {'bootstrap': False, 'max_features': 2, 'n_est...      -2.863479e+09   \n",
       "14  {'bootstrap': False, 'max_features': 3, 'n_est...      -3.380601e+09   \n",
       "15  {'bootstrap': False, 'max_features': 3, 'n_est...      -2.714781e+09   \n",
       "16  {'bootstrap': False, 'max_features': 4, 'n_est...      -3.438860e+09   \n",
       "17  {'bootstrap': False, 'max_features': 4, 'n_est...      -2.575274e+09   \n",
       "\n",
       "    split1_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0       -4.313661e+09  ...    -4.116607e+09    2.563509e+08               18   \n",
       "1       -3.119997e+09  ...    -3.027606e+09    1.668264e+08               11   \n",
       "2       -2.911493e+09  ...    -2.811365e+09    1.493787e+08                8   \n",
       "3       -3.762455e+09  ...    -3.720020e+09    1.536307e+08               16   \n",
       "4       -3.042027e+09  ...    -2.838169e+09    1.510512e+08                9   \n",
       "5       -2.597113e+09  ...    -2.543872e+09    1.482446e+08                3   \n",
       "6       -3.487085e+09  ...    -3.524766e+09    1.202082e+08               14   \n",
       "7       -2.723348e+09  ...    -2.675294e+09    1.335638e+08                4   \n",
       "8       -2.560697e+09  ...    -2.486072e+09    1.252884e+08                2   \n",
       "9       -3.553599e+09  ...    -3.399507e+09    1.295960e+08               12   \n",
       "10      -2.789060e+09  ...    -2.728464e+09    1.512255e+08                6   \n",
       "11      -2.518849e+09  ...    -2.478082e+09    1.105207e+08                1   \n",
       "12      -3.943092e+09  ...    -3.858075e+09    2.061109e+08               17   \n",
       "13      -3.184515e+09  ...    -3.002355e+09    1.371263e+08               10   \n",
       "14      -3.429445e+09  ...    -3.566669e+09    2.493520e+08               15   \n",
       "15      -2.712905e+09  ...    -2.748078e+09    8.888762e+07                7   \n",
       "16      -3.557646e+09  ...    -3.488065e+09    3.979269e+07               13   \n",
       "17      -2.733132e+09  ...    -2.690139e+09    8.754169e+07                5   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0        -1.083079e+09       -1.047389e+09       -1.127826e+09   \n",
       "1        -6.173649e+08       -5.641315e+08       -5.666449e+08   \n",
       "2        -4.440819e+08       -4.238242e+08       -4.273691e+08   \n",
       "3        -1.011239e+09       -9.914131e+08       -9.562032e+08   \n",
       "4        -5.443797e+08       -5.544777e+08       -5.250524e+08   \n",
       "5        -4.018289e+08       -3.936587e+08       -3.813845e+08   \n",
       "6        -9.297786e+08       -8.891628e+08       -9.481490e+08   \n",
       "7        -5.077070e+08       -4.978420e+08       -4.958105e+08   \n",
       "8        -3.848096e+08       -3.722657e+08       -3.703482e+08   \n",
       "9        -8.762917e+08       -8.958030e+08       -8.885024e+08   \n",
       "10       -5.103001e+08       -5.063813e+08       -4.867061e+08   \n",
       "11       -3.878266e+08       -3.755611e+08       -3.677518e+08   \n",
       "12       -0.000000e+00       -0.000000e+00       -0.000000e+00   \n",
       "13       -2.439095e+02       -0.000000e+00       -0.000000e+00   \n",
       "14       -0.000000e+00       -0.000000e+00       -0.000000e+00   \n",
       "15       -0.000000e+00       -0.000000e+00       -0.000000e+00   \n",
       "16       -0.000000e+00       -0.000000e+00       -0.000000e+00   \n",
       "17       -0.000000e+00       -3.876145e+00       -0.000000e+00   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0        -1.109980e+09       -1.106520e+09     -1.094959e+09     2.772560e+07  \n",
       "1        -5.771149e+08       -5.799831e+08     -5.810479e+08     1.912663e+07  \n",
       "2        -4.469485e+08       -4.238588e+08     -4.332165e+08     1.016464e+07  \n",
       "3        -1.022028e+09       -9.184196e+08     -9.798606e+08     3.802849e+07  \n",
       "4        -5.060819e+08       -5.235322e+08     -5.307048e+08     1.698137e+07  \n",
       "5        -4.004283e+08       -3.855221e+08     -3.925645e+08     8.043081e+06  \n",
       "6        -9.182473e+08       -9.067466e+08     -9.184168e+08     2.002556e+07  \n",
       "7        -5.085082e+08       -4.941817e+08     -5.008099e+08     6.075659e+06  \n",
       "8        -3.916076e+08       -3.767458e+08     -3.791554e+08     7.973333e+06  \n",
       "9        -9.027841e+08       -8.944754e+08     -8.915713e+08     8.887662e+06  \n",
       "10       -5.259273e+08       -5.041240e+08     -5.066878e+08     1.256299e+07  \n",
       "11       -3.860005e+08       -3.801933e+08     -3.794667e+08     7.288349e+06  \n",
       "12       -0.000000e+00       -0.000000e+00      0.000000e+00     0.000000e+00  \n",
       "13       -0.000000e+00       -0.000000e+00     -4.878189e+01     9.756378e+01  \n",
       "14       -0.000000e+00       -0.000000e+00      0.000000e+00     0.000000e+00  \n",
       "15       -0.000000e+00       -0.000000e+00      0.000000e+00     0.000000e+00  \n",
       "16       -0.000000e+00       -0.000000e+00      0.000000e+00     0.000000e+00  \n",
       "17       -9.462528e+02       -2.422407e-01     -1.900742e+02     3.780922e+02  \n",
       "\n",
       "[18 rows x 23 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cvres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64160.789107027056 {'max_features': 2, 'n_estimators': 3}\n",
      "55023.68549986461 {'max_features': 2, 'n_estimators': 10}\n",
      "53022.30358178781 {'max_features': 2, 'n_estimators': 30}\n",
      "60991.96872608704 {'max_features': 4, 'n_estimators': 3}\n",
      "53274.46596407676 {'max_features': 4, 'n_estimators': 10}\n",
      "50436.81299863488 {'max_features': 4, 'n_estimators': 30}\n",
      "59369.73786915139 {'max_features': 6, 'n_estimators': 3}\n",
      "51723.24590927607 {'max_features': 6, 'n_estimators': 10}\n",
      "49860.52552881573 {'max_features': 6, 'n_estimators': 30}\n",
      "58305.29360816507 {'max_features': 8, 'n_estimators': 3}\n",
      "52234.69698472098 {'max_features': 8, 'n_estimators': 10}\n",
      "49780.33614076912 {'max_features': 8, 'n_estimators': 30}\n",
      "62113.40513981505 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "54793.75392047745 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "59721.59735753971 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "52422.113056631315 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "59059.84115437218 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "51866.550404424175 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 이 예에서는 `max_features=8`, `n_estimators=30` 일 때 최적의 솔루션이다.\n",
    "- 이 때 RMSE 점수가 50,109로 앞서 기본 하이퍼파라미터 설정으로 얻은 50,293 보다 조금 더 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.7.1.5 데이터 준비 단계에 그리드 탐색 적용\n",
    "\n",
    "- 데이터 준비 단계를 하나의 하이퍼파라미터처럼 다룰 수 있다.\n",
    "- ex) 그리드 탐색이 확실하지 않은 특성을 추가할 지 말지 자동으로 정할 수 있다.\n",
    "  - `CombinedAttributedsAdder` 변환기의 `add_bedrooms_per_room` 하이퍼파라미터를 사용하여 특성을 추가할 지 결정\n",
    "- 비슷하게 이상치나 값이 빈 특성을 다루거나 특성 선택 등을 자동으로 처리하는 데 그리드 탐색이 활용된다.\n",
    "  - 데이터 준비 단계와 모델을 연결한 파이프라인을 그리드 탐색을 적용할 때 데이터 준비 단계를 캐싱하면 탐색 시간을 줄일 수 있다.\n",
    "  - 참고 : [Pipeline에서 캐싱을 사용하기](https://goo.gl/cq9Nyb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2.7.2 랜덤 선택\n",
    "\n",
    "- 그리드 탐색 방법은 비교적 적은 수의 조합을 탐구할 때 괜찮다.\n",
    "- 하지만 하이퍼파라미터 탐색 공간이 커지면 `RandomizedSearchCV`를 사용하는 편이 더 좋다.\n",
    "- 특히 규제처럼 설정값이 **연속형**인 경우 랜덤 탐색이 권장된다.\n",
    "  - 랜덤 탐색을 10회 반복하여 찾은 최적의 하이퍼파라미터는 `n_estimators`가 180, `max_features`가 7이다.\n",
    "- `RandomizedSearchCV`는 `GridSearchCV`와 거의 같은 방식으로 사용하지만 가능한 모든 조합을 시도하는 대신 각 반복마다 하이퍼파라미터에 임의의 수를 대입하여 지정한 횟수 만큼 평가한다.\n",
    "- 이 방식의 주요 장점은 다음 두 가지이다.\n",
    "  - 랜덤 탐색을 1,000회 반복하도록 실행하면 하이퍼파라미터마다 각기 다른 1,000개의 값을 탐색한다.  \n",
    "  (그리드 탐색에서는 하이퍼파라미터마다 몇 개의 값만 탐색한다.)\n",
    "  - 단순히 반복 횟수를 조절하는 것만으로 하이퍼파라미터 탐색에 투입할 컴퓨팅 자원을 제어할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_distribs = {\n",
    "    'n_estimators': randint(low=1, high=200),\n",
    "    'max_features': randint(low=1, high=8)\n",
    "}\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_reg,\n",
    "                                param_distributions=param_distribs,\n",
    "                                n_iter=10,\n",
    "                                cv=5,\n",
    "                                scoring='neg_mean_squared_error',\n",
    "                                random_state=42)\n",
    "rnd_search.fit(housing_prepared, housing_labels)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49150.70756927707 {'max_features': 7, 'n_estimators': 180}\n",
      "51389.889203389284 {'max_features': 5, 'n_estimators': 15}\n",
      "50796.155224308866 {'max_features': 3, 'n_estimators': 72}\n",
      "50835.13360315349 {'max_features': 5, 'n_estimators': 21}\n",
      "49280.9449827171 {'max_features': 7, 'n_estimators': 122}\n",
      "50774.90662363929 {'max_features': 3, 'n_estimators': 75}\n",
      "50682.78888164288 {'max_features': 3, 'n_estimators': 88}\n",
      "49608.99608105296 {'max_features': 5, 'n_estimators': 100}\n",
      "50473.61930350219 {'max_features': 3, 'n_estimators': 150}\n",
      "64429.84143294435 {'max_features': 5, 'n_estimators': 2}\n"
     ]
    }
   ],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- best params : `49150.70756927707 {'max_features': 7, 'n_estimators': 180}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `RandomizedSearchCV`를 위한 Scipy 분포 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import geom\n",
    "\n",
    "geom_distrib = geom(0.5).rvs(10000, random_state=42)\n",
    "plt.hist(geom_distrib, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import expon\n",
    "\n",
    "expon_distrib = expon(scale=1).rvs(10000, random_state=42)\n",
    "plt.hist(expon_distrib, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2.7.3 앙상블 방법\n",
    "\n",
    "- 모델을 세밀하게 튜닝하는 또 다른 방법은 **최상의 모델을 연결해보는 것**이다.\n",
    "  - 결정 트리의 앙상블인 랜덤 포레스트가 결정 트리 하나보다 더 성능이 좋음\n",
    "- 모델의 그룹(또는 앙상블(ensemble))이 최상의 단일 모델보다 더 나은 성능을 발휘할 때가 많다.\n",
    "- 특히 **개개의 모델이 각기 다른 형태의 오차를 만들 때** 그렇다.\n",
    "- 7장에서 자세히 다룸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2.7.4 최상의 모델과 오차 분석\n",
    "\n",
    "- 최상의 모델을 분석하면 문제에 대한 좋은 통찰을 얻는 경우가 많다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.7.4.1 특성 중요도\n",
    "\n",
    "- `RandomForestRegressor`가 정확한 예측을 만들기 위한 각 특성의 상대적 중요도를 알려준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.97303211e-02, 6.54203229e-02, 4.49751385e-02, 1.48995369e-02,\n",
       "       1.45590289e-02, 1.54571110e-02, 1.38542321e-02, 3.42373218e-01,\n",
       "       5.67088440e-02, 1.12368626e-01, 7.78529703e-02, 6.64634793e-03,\n",
       "       1.59226794e-01, 7.72169072e-05, 2.58711400e-03, 3.26317745e-03])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 중요도와 특성 이름 함께 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'rooms_per_hhold', 'pop_per_hhold', 'bedrooms_per_room', '<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']\n"
     ]
    }
   ],
   "source": [
    "extra_attribs = ['rooms_per_hhold', 'pop_per_hhold', 'bedrooms_per_room']\n",
    "cat_encoder = full_pipeline.named_transformers_['cat']\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3423732180943481, 'median_income'),\n",
       " (0.1592267936887254, 'INLAND'),\n",
       " (0.11236862631360213, 'pop_per_hhold'),\n",
       " (0.0778529703294465, 'bedrooms_per_room'),\n",
       " (0.06973032114652118, 'longitude'),\n",
       " (0.06542032286785304, 'latitude'),\n",
       " (0.05670884396655083, 'rooms_per_hhold'),\n",
       " (0.044975138485792335, 'housing_median_age'),\n",
       " (0.015457110991631608, 'population'),\n",
       " (0.014899536869926231, 'total_rooms'),\n",
       " (0.01455902888980478, 'total_bedrooms'),\n",
       " (0.013854232070124957, 'households'),\n",
       " (0.006646347928268235, '<1H OCEAN'),\n",
       " (0.0032631774545039565, 'NEAR OCEAN'),\n",
       " (0.002587113995654641, 'NEAR BAY'),\n",
       " (7.721690724605114e-05, 'ISLAND')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 이 정보를 바탕으로 덜 중요한 특성들을 제외할 수 있다.\n",
    "  - ex) `ocean_proximity` 카테고리 중 하나만 실제로 유용하므로 다른 카테고리는 제외할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.7.4.2 오차 분석\n",
    "\n",
    "- 시스템이 특정한 오차를 만들었다면 왜 그런 문제가 생겼는 지 이해하고 **문제를 해결하는 방법**이 무엇인 지 찾아야 한다.\n",
    "  - 추가 특성 포함\n",
    "  - 불필요한 특성 제거\n",
    "  - 이상치 제외"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2.7.5 테스트 세트로 시스템 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.5.1 테스트 세트를 이용한 모델 최종 평가\n",
    "\n",
    "- 테스트 세트에서 예측 변수와 레이블을 얻은 후 `full_pipeline`을 사용해 데이터를 변환\n",
    "  - 테스트 세트에서 훈련하면 안되므로 `fit_transform()`이 아니라 `transform()`을 호출\n",
    "- 테스트 세트에서 최종 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47905.4483716546"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop('median_house_value', axis=1)\n",
    "y_test = strat_test_set['median_house_value'].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.7.5.2 테스트 RMSE에 대한 95% 신뢰 구간 계산\n",
    "\n",
    "- 어떤 경우에는 이런 일반화 오차의 추정이 론칭을 결정하기에 충분하지 않을 수 있다.\n",
    "- 이 추정값이 얼마나 정확한 지 알고 싶을 때 `scipy.stats.t.interval()`를 사용해 일반화 오차의 **95% 신뢰 구간(confidence interval)**을 계산할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45892.48146371, 49837.17600829])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "confidence = 0.95\n",
    "squared_errors = (final_predictions - y_test)**2\n",
    "np.sqrt(stats.t.interval(confidence,\n",
    "                         len(squared_errors) - 1,\n",
    "                         loc=squared_errors.mean(),\n",
    "                         scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 다음과 같이 수동으로 계산할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45892.48146370956, 49837.17600829304)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = len(squared_errors)\n",
    "mean = squared_errors.mean()\n",
    "tscore = stats.t.ppf((1+confidence)/2, df=m-1)\n",
    "tmargin = tscore * squared_errors.std(ddof=1) / np.sqrt(m)\n",
    "np.sqrt(mean-tmargin), np.sqrt(mean+tmargin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 또는 t-점수 대신 z-점수를 사용할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45893.08476618239, 49836.62045145621)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zscore = stats.norm.ppf((1+confidence)/2)\n",
    "zmargin = zscore * squared_errors.std(ddof=1) / np.sqrt(m)\n",
    "np.sqrt(mean-zmargin), np.sqrt(mean+zmargin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.7.5.3 테스트 세트 성능 향상을 위한 하이퍼파라미터 튜닝 제한\n",
    "\n",
    "- 하이퍼파라미터 튜닝을 많이 했다면 교차 검증을 사용해 측정한 것보다 조금 성능이 낮은 것이 보통이다.\n",
    "  - 우리 시스템이 검증 데이터에서 좋은 성능을 내도록 세밀하게 튜닝되었기 때문에 새로운 데이터셋에는 잘 작동하지 않을 가능성이 크다.\n",
    "- 이런 경우가 생기더라도 테스트 세트에서 성능 수치를 좋게 하려고 하이퍼파라미터를 튜닝하려 시도해서는 안된다.\n",
    "- 그렇게 향상된 성능은 새로운 데이터에 일반화되기 어렵다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
