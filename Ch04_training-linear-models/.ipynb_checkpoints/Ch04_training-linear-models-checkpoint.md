# 4. 모델 훈련

**선형 회귀**

- 가장 간단한 모델 중 하나인 **선형 회귀**의 작동 원리 학습
- 이 모델을 훈련 시키는 2가지 방법 설명
  - 직접 계산할 수 있는 공식을 사용하여 훈련 세트에 가장 잘 맞는 모델 파라미터(즉, 훈련 세트에 대해 비용 함수를 최소화하는 모델 파라미터)를 해석적으로 구함
  - 경사 하강법(GD)이라 불리는 반복적인 최적화 방식을 사용하여 모델 파라미터를 조금씩 바꾸면서 비용 함수를 훈련 세트에 대해 최소화
    - 결국에는 앞의 방법과 동일한 파라미터로 수렴
    - 경사 하강법의 변종으로 신경망 학습 시 계속 사용되는 다음 내용들에 대해서도 학습
      - 배치(batch) 경사 하강법
      - 미니배치(mini-batch) 경사 하강법
      - 확률적(stochastic) 경사 하강법(SGD)
      
<br>

**다항 회귀**

- 비선형 데이터셋에 훈련시킬 수 있는 **다항 회귀**에 대해 학습
- 이 모델은 선형 회귀보다 파라미터가 많아서 훈련 데이터에 과대 적합되기 더 쉬움
- 따라서 학습 곡선(learning curve)을 사용해 **모델이 과대적합되는 지 감지하는 방법** 학습
- 훈련 세트의 과대적합을 감소시킬 수 있는 **규제 기법**에 대해서도 학습

<br>

**로지스틱 회귀**, **소프트맥스 회귀**

- 분류 작업에 널리 사용하는 모델인 **로지스틱 회귀**와 **소프트맥스 회귀**에 대해 학습